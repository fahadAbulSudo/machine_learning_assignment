{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"B8MMe4HHJLzj"},"outputs":[],"source":["# Imports\n","import tensorflow_datasets as tfds\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import inspect\n","from tqdm import tqdm\n","import numpy as np\n","import os\n","import tensorflow as tf\n","import sys\n","import cv2\n","from sklearn.metrics import classification_report, log_loss, accuracy_score\n","from sklearn.model_selection import train_test_split\n","import random\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n","from tensorflow.keras.optimizers import Adamax\n","from tensorflow.keras.metrics import categorical_crossentropy\n","# Set batch size for training and validation\n","batch_size = 32"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_bRiSjggJQnM"},"outputs":[],"source":["model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJ2VTB3zJUV7","outputId":"c4caba47-990f-479b-956e-5daeddec6a53"},"outputs":[{"data":{"text/plain":["{'DenseNet121': <function keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'DenseNet169': <function keras.applications.densenet.DenseNet169(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'DenseNet201': <function keras.applications.densenet.DenseNet201(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'EfficientNetB0': <function keras.applications.efficientnet.EfficientNetB0(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetB1': <function keras.applications.efficientnet.EfficientNetB1(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetB2': <function keras.applications.efficientnet.EfficientNetB2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetB3': <function keras.applications.efficientnet.EfficientNetB3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetB4': <function keras.applications.efficientnet.EfficientNetB4(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetB5': <function keras.applications.efficientnet.EfficientNetB5(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetB6': <function keras.applications.efficientnet.EfficientNetB6(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetB7': <function keras.applications.efficientnet.EfficientNetB7(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'EfficientNetV2B0': <function keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'EfficientNetV2B1': <function keras.applications.efficientnet_v2.EfficientNetV2B1(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'EfficientNetV2B2': <function keras.applications.efficientnet_v2.EfficientNetV2B2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'EfficientNetV2B3': <function keras.applications.efficientnet_v2.EfficientNetV2B3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'EfficientNetV2L': <function keras.applications.efficientnet_v2.EfficientNetV2L(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'EfficientNetV2M': <function keras.applications.efficientnet_v2.EfficientNetV2M(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'EfficientNetV2S': <function keras.applications.efficientnet_v2.EfficientNetV2S(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'InceptionResNetV2': <function keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'InceptionV3': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'MobileNet': <function keras.applications.mobilenet.MobileNet(input_shape=None, alpha=1.0, depth_multiplier=1, dropout=0.001, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'MobileNetV2': <function keras.applications.mobilenet_v2.MobileNetV2(input_shape=None, alpha=1.0, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax', **kwargs)>,\n"," 'MobileNetV3Large': <function keras.applications.mobilenet_v3.MobileNetV3Large(input_shape=None, alpha=1.0, minimalistic=False, include_top=True, weights='imagenet', input_tensor=None, classes=1000, pooling=None, dropout_rate=0.2, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'MobileNetV3Small': <function keras.applications.mobilenet_v3.MobileNetV3Small(input_shape=None, alpha=1.0, minimalistic=False, include_top=True, weights='imagenet', input_tensor=None, classes=1000, pooling=None, dropout_rate=0.2, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'NASNetLarge': <function keras.applications.nasnet.NASNetLarge(input_shape=None, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'NASNetMobile': <function keras.applications.nasnet.NASNetMobile(input_shape=None, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX002': <function keras.applications.regnet.RegNetX002(model_name='regnetx002', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX004': <function keras.applications.regnet.RegNetX004(model_name='regnetx004', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX006': <function keras.applications.regnet.RegNetX006(model_name='regnetx006', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX008': <function keras.applications.regnet.RegNetX008(model_name='regnetx008', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX016': <function keras.applications.regnet.RegNetX016(model_name='regnetx016', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX032': <function keras.applications.regnet.RegNetX032(model_name='regnetx032', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX040': <function keras.applications.regnet.RegNetX040(model_name='regnetx040', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX064': <function keras.applications.regnet.RegNetX064(model_name='regnetx064', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX080': <function keras.applications.regnet.RegNetX080(model_name='regnetx080', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX120': <function keras.applications.regnet.RegNetX120(model_name='regnetx120', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX160': <function keras.applications.regnet.RegNetX160(model_name='regnetx160', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetX320': <function keras.applications.regnet.RegNetX320(model_name='regnetx320', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY002': <function keras.applications.regnet.RegNetY002(model_name='regnety002', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY004': <function keras.applications.regnet.RegNetY004(model_name='regnety004', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY006': <function keras.applications.regnet.RegNetY006(model_name='regnety006', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY008': <function keras.applications.regnet.RegNetY008(model_name='regnety008', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY016': <function keras.applications.regnet.RegNetY016(model_name='regnety016', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY032': <function keras.applications.regnet.RegNetY032(model_name='regnety032', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY040': <function keras.applications.regnet.RegNetY040(model_name='regnety040', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY064': <function keras.applications.regnet.RegNetY064(model_name='regnety064', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY080': <function keras.applications.regnet.RegNetY080(model_name='regnety080', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY120': <function keras.applications.regnet.RegNetY120(model_name='regnety120', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY160': <function keras.applications.regnet.RegNetY160(model_name='regnety160', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'RegNetY320': <function keras.applications.regnet.RegNetY320(model_name='regnety320', include_top=True, include_preprocessing=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'ResNet101': <function keras.applications.resnet.ResNet101(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, **kwargs)>,\n"," 'ResNet101V2': <function keras.applications.resnet_v2.ResNet101V2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'ResNet152': <function keras.applications.resnet.ResNet152(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, **kwargs)>,\n"," 'ResNet152V2': <function keras.applications.resnet_v2.ResNet152V2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'ResNet50': <function keras.applications.resnet.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, **kwargs)>,\n"," 'ResNet50V2': <function keras.applications.resnet_v2.ResNet50V2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'ResNetRS101': <function keras.applications.resnet_rs.ResNetRS101(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'ResNetRS152': <function keras.applications.resnet_rs.ResNetRS152(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'ResNetRS200': <function keras.applications.resnet_rs.ResNetRS200(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'ResNetRS270': <function keras.applications.resnet_rs.ResNetRS270(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'ResNetRS350': <function keras.applications.resnet_rs.ResNetRS350(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'ResNetRS420': <function keras.applications.resnet_rs.ResNetRS420(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'ResNetRS50': <function keras.applications.resnet_rs.ResNetRS50(include_top=True, weights='imagenet', classes=1000, input_shape=None, input_tensor=None, pooling=None, classifier_activation='softmax', include_preprocessing=True)>,\n"," 'VGG16': <function keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'VGG19': <function keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n"," 'Xception': <function keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["model_dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vEJxhazPa4hG","outputId":"8d02b488-3d54-4243-f022-f1bb4548abb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXn4yXIObDYl","outputId":"d62ce1ba-5484-4e3d-9893-fac8127e8641"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/gdrive/MyDrive/Data/archive.zip\n","replace animals/animals/antelope/02f4b3be2d.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace animals/animals/antelope/03d7fc0888.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}],"source":["!unzip \"/content/gdrive/MyDrive/Data/archive.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OxG2atebLbt","outputId":"e7532209-1cb4-4600-825c-30e30f17644b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['crow', 'tiger', 'rhinoceros', 'kangaroo', 'seahorse', 'bee', 'possum', 'hornbill', 'badger', 'horse', 'octopus', 'boar', 'ox', 'wombat', 'fox', 'donkey', 'koala', 'crab', 'sandpiper', 'okapi', 'dragonfly', 'lion', 'orangutan', 'owl', 'woodpecker', 'bear', 'eagle', 'hyena', 'hare', 'oyster', 'turkey', 'pig', 'hamster', 'caterpillar', 'lobster', 'sheep', 'hedgehog', 'wolf', 'seal', 'snake', 'cockroach', 'goat', 'lizard', 'porcupine', 'penguin', 'raccoon', 'otter', 'reindeer', 'gorilla', 'butterfly', 'squid', 'duck', 'rat', 'chimpanzee', 'jellyfish', 'squirrel', 'beetle', 'leopard', 'pelecaniformes', 'bison', 'swan', 'hippopotamus', 'flamingo', 'grasshopper', 'panda', 'shark', 'cat', 'dog', 'sparrow', 'mouse', 'goose', 'pigeon', 'moth', 'hummingbird', 'cow', 'whale', 'zebra', 'deer', 'antelope', 'goldfish', 'turtle', 'mosquito', 'coyote', 'dolphin', 'bat', 'elephant', 'parrot', 'starfish', 'fly', 'ladybugs']\n","90\n"]}],"source":["data_dir = '/content/animals/animals'\n","Name = os.listdir(data_dir)\n","#Name.sort()\n","print(Name)\n","print(len(Name))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yyePdlr5bUiU"},"outputs":[],"source":["import os\n","import numpy as np\n","import shutil\n","\n","rootdir= '/content/animals/'\n","classes = Name\n","\n","for i in classes:\n","  os.makedirs(rootdir +'/train/' + i)\n","  os.makedirs(rootdir +'/test/' + i)\n","  source = '/content/animals/animals/' + i\n","  allFileNames = os.listdir(source)\n","  np.random.shuffle(allFileNames)\n","\n","  test_ratio = 0.05\n","  \n","  train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n","                                                      [int(len(allFileNames)* (1 - test_ratio))])\n","\n","  train_FileNames = [source+'/'+ name for name in train_FileNames.tolist()]\n","  test_FileNames = [source+'/' + name for name in test_FileNames.tolist()]\n","\n","  for name in train_FileNames:\n","    shutil.copy(name, rootdir +'/train/' + i)\n","\n","  for name in test_FileNames:\n","    shutil.copy(name, rootdir +'/test/' + i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTW37OJFd4p4"},"outputs":[],"source":["# import shutil\n","# shutil.rmtree('/content/animals/test')\n","# shutil.rmtree('/content/animals/train')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qf1ATr0kcAit","outputId":"88b4c499-21d7-4831-9b89-2fdbec1f7998"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5130 files belonging to 90 classes.\n","Using 4617 files for training.\n","Found 5130 files belonging to 90 classes.\n","Using 513 files for validation.\n","Found 5130 files belonging to 90 classes.\n","Using 4617 files for training.\n","Found 5130 files belonging to 90 classes.\n","Using 513 files for validation.\n"]}],"source":["train_dir = '/content/animals/train'\n","train_processed_224  = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n","                                                                    batch_size = 32,\n","                                                                    image_size = (224,224),\n","                                                                    shuffle = True, \n","                                                                    seed = 505,\n","                                                                    validation_split=0.1,\n","                                                                    subset = \"training\")\n","validation_processed_224 = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n","                                                                    batch_size = 32,\n","                                                                    image_size = (224,224),\n","                                                                    shuffle = True, \n","                                                                    seed = 505,\n","                                                                    validation_split=0.1,\n","                                                                    subset = \"validation\")\n","\n","train_processed_331  = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n","                                                                    batch_size = 32,\n","                                                                    image_size = (331,331),\n","                                                                    shuffle = True, \n","                                                                    seed = 505,\n","                                                                    validation_split=0.1,\n","                                                                    subset = \"training\")\n","validation_processed_331 = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n","                                                                    batch_size = 32,\n","                                                                    image_size = (331,331),\n","                                                                    shuffle = True, \n","                                                                    seed = 505,\n","                                                                    validation_split=0.1,\n","                                                                    subset = \"validation\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rwR4Qf5JZyj"},"outputs":[],"source":["# (train, validation), metadata = tfds.load('cats_vs_dogs', split=['train[:70%]', 'train[70%:]'], with_info=True, as_supervised=True)\n","\n","# Number of training examples and labels\n","num_train = len(train_processed_224)\n","num_validation = len(validation_processed_224)\n","num_classes = len(Name)\n","num_iterations = int(num_train/batch_size)\n","\n","# # Print important info\n","# print(f'Num train images: {num_train} \\\n","#         \\nNum validation images: {num_validation} \\\n","#         \\nNum classes: {num_classes} \\\n","#         \\nNum iterations per epoch: {num_iterations}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVPM4v-BSTp1"},"outputs":[],"source":["def normalize_img(image, label, img_size):\n","    # Resize image to the desired img_size and normalize it\n","    # One hot encode the label\n","    image = tf.image.resize(image, img_size)\n","    image = tf.cast(image, tf.float32) / 255\n","    label = tf.one_hot(label, depth=num_classes)\n","    return image, label\n","    \n","def preprocess_data(train, validation, batch_size, img_size):\n","    # Apply the normalize_img function on all train and validation data and create batches\n","    train_processed = train.map(lambda image, label: normalize_img(image, label, img_size))\n","    \n","    # If your data is already batched (eg, when using the image_dataset_from_directory function), remove .batch(batch_size)\n","    train_processed = train_processed.batch(batch_size).repeat()\n","    \n","    validation_processed = validation.map(lambda image, label: normalize_img(image, label, img_size))\n","    \n","    # If your data is already batched (eg, when using the image_dataset_from_directory function), remove .batch(batch_size)\n","    validation_processed = validation_processed.batch(batch_size)\n","    \n","    return train_processed, validation_processed\n","    \n","# Run preprocessing\n","train_processed_224, validation_processed_224 = preprocess_data(train_dataset, validation_dataset, batch_size, img_size=[224,224])\n","train_processed_331, validation_processed_331 = preprocess_data(train_dataset, validation_dataset, batch_size, img_size=[331,331])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbobRbmcScMk","outputId":"be2dc12a-5411-47c6-ee86-240bd370706f"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/35 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 18s 3s/step - loss: 16.7677 - accuracy: 0.0156 - val_loss: 12.9258 - val_accuracy: 0.0156\n","Epoch 2/3\n","4/4 [==============================] - 6s 2s/step - loss: 12.1681 - accuracy: 0.0000e+00 - val_loss: 10.9227 - val_accuracy: 0.0156\n","Epoch 3/3\n","4/4 [==============================] - 11s 4s/step - loss: 9.9494 - accuracy: 0.0234 - val_loss: 9.6820 - val_accuracy: 0.0117\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 1/35 [00:55<31:43, 55.99s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 24s 3s/step - loss: 20.6687 - accuracy: 0.0234 - val_loss: 16.7132 - val_accuracy: 0.0175\n","Epoch 2/3\n","4/4 [==============================] - 7s 2s/step - loss: 18.6038 - accuracy: 0.0156 - val_loss: 14.6224 - val_accuracy: 0.0136\n","Epoch 3/3\n","4/4 [==============================] - 7s 2s/step - loss: 13.7843 - accuracy: 0.0156 - val_loss: 12.1860 - val_accuracy: 0.0156\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 2/35 [01:55<31:57, 58.10s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 28s 4s/step - loss: 10.9907 - accuracy: 0.0312 - val_loss: 11.3638 - val_accuracy: 0.0117\n","Epoch 2/3\n","4/4 [==============================] - 9s 3s/step - loss: 10.8619 - accuracy: 0.0156 - val_loss: 9.0676 - val_accuracy: 0.0097\n","Epoch 3/3\n","4/4 [==============================] - 10s 3s/step - loss: 8.1459 - accuracy: 0.0078 - val_loss: 7.8500 - val_accuracy: 0.0136\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▊         | 3/35 [02:58<32:08, 60.28s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 16s 2s/step - loss: 4.4208 - accuracy: 0.0547 - val_loss: 4.3058 - val_accuracy: 0.1170\n","Epoch 2/3\n","4/4 [==============================] - 5s 2s/step - loss: 4.1896 - accuracy: 0.1406 - val_loss: 4.0255 - val_accuracy: 0.2008\n","Epoch 3/3\n","4/4 [==============================] - 5s 2s/step - loss: 3.9245 - accuracy: 0.1953 - val_loss: 3.7732 - val_accuracy: 0.2982\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█▏        | 4/35 [03:29<25:09, 48.71s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 22s 3s/step - loss: 4.5275 - accuracy: 0.0234 - val_loss: 4.1901 - val_accuracy: 0.1404\n","Epoch 2/3\n","4/4 [==============================] - 5s 2s/step - loss: 4.1660 - accuracy: 0.1328 - val_loss: 3.9215 - val_accuracy: 0.2710\n","Epoch 3/3\n","4/4 [==============================] - 5s 2s/step - loss: 3.8686 - accuracy: 0.2422 - val_loss: 3.6802 - val_accuracy: 0.3567\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 5/35 [04:26<25:53, 51.80s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 21s 3s/step - loss: 4.3482 - accuracy: 0.1094 - val_loss: 4.2512 - val_accuracy: 0.1481\n","Epoch 2/3\n","4/4 [==============================] - 5s 2s/step - loss: 4.0873 - accuracy: 0.2266 - val_loss: 3.9693 - val_accuracy: 0.2846\n","Epoch 3/3\n","4/4 [==============================] - 6s 2s/step - loss: 3.8004 - accuracy: 0.2969 - val_loss: 3.7421 - val_accuracy: 0.3899\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 6/35 [05:22<25:45, 53.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 24s 3s/step - loss: 4.3965 - accuracy: 0.0781 - val_loss: 4.1962 - val_accuracy: 0.1618\n","Epoch 2/3\n","4/4 [==============================] - 7s 2s/step - loss: 4.1840 - accuracy: 0.1328 - val_loss: 3.9331 - val_accuracy: 0.3177\n","Epoch 3/3\n","4/4 [==============================] - 7s 2s/step - loss: 3.7413 - accuracy: 0.3828 - val_loss: 3.6894 - val_accuracy: 0.4347\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|██        | 7/35 [06:21<25:44, 55.15s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 30s 4s/step - loss: 4.3405 - accuracy: 0.1250 - val_loss: 4.1599 - val_accuracy: 0.2222\n","Epoch 2/3\n","4/4 [==============================] - 8s 3s/step - loss: 4.0584 - accuracy: 0.2734 - val_loss: 3.8953 - val_accuracy: 0.2943\n","Epoch 3/3\n","4/4 [==============================] - 8s 3s/step - loss: 3.7743 - accuracy: 0.3359 - val_loss: 3.6602 - val_accuracy: 0.4074\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 8/35 [07:15<24:32, 54.52s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","4/4 [==============================] - 37s 6s/step - loss: 4.3617 - accuracy: 0.1250 - val_loss: 4.0496 - val_accuracy: 0.2690\n","Epoch 2/3\n","4/4 [==============================] - 11s 3s/step - loss: 4.0261 - accuracy: 0.3203 - val_loss: 3.7160 - val_accuracy: 0.4386\n","Epoch 3/3\n","4/4 [==============================] - 11s 3s/step - loss: 3.5523 - accuracy: 0.4766 - val_loss: 3.4236 - val_accuracy: 0.5263\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 9/35 [09:01<30:42, 70.86s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n","165240832/165234480 [==============================] - 2s 0us/step\n","165249024/165234480 [==============================] - 2s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 44s 7s/step - loss: 4.3572 - accuracy: 0.1719 - val_loss: 4.0572 - val_accuracy: 0.3197\n","Epoch 2/3\n","4/4 [==============================] - 14s 4s/step - loss: 3.9641 - accuracy: 0.3516 - val_loss: 3.7512 - val_accuracy: 0.4483\n","Epoch 3/3\n","4/4 [==============================] - 14s 4s/step - loss: 3.6126 - accuracy: 0.4688 - val_loss: 3.4618 - val_accuracy: 0.5614\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▊       | 10/35 [10:54<34:55, 83.83s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n","258080768/258076736 [==============================] - 4s 0us/step\n","258088960/258076736 [==============================] - 4s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 52s 8s/step - loss: 4.2880 - accuracy: 0.1562 - val_loss: 4.0872 - val_accuracy: 0.2242\n","Epoch 2/3\n","4/4 [==============================] - 18s 6s/step - loss: 3.8945 - accuracy: 0.2891 - val_loss: 3.7230 - val_accuracy: 0.3879\n","Epoch 3/3\n","4/4 [==============================] - 18s 6s/step - loss: 3.6066 - accuracy: 0.4531 - val_loss: 3.3978 - val_accuracy: 0.5750\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███▏      | 11/35 [12:39<36:06, 90.27s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n","24281088/24274472 [==============================] - 0s 0us/step\n","24289280/24274472 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 18s 2s/step - loss: 4.4201 - accuracy: 0.0547 - val_loss: 4.2187 - val_accuracy: 0.1189\n","Epoch 2/3\n","4/4 [==============================] - 4s 1s/step - loss: 4.1235 - accuracy: 0.1797 - val_loss: 3.9205 - val_accuracy: 0.2300\n","Epoch 3/3\n","4/4 [==============================] - 5s 1s/step - loss: 3.8236 - accuracy: 0.2656 - val_loss: 3.6510 - val_accuracy: 0.4250\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 12/35 [13:13<28:03, 73.19s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b1_notop.h5\n","28459008/28456008 [==============================] - 0s 0us/step\n","28467200/28456008 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 18s 2s/step - loss: 4.3814 - accuracy: 0.0703 - val_loss: 4.1550 - val_accuracy: 0.1715\n","Epoch 2/3\n","4/4 [==============================] - 5s 2s/step - loss: 4.0392 - accuracy: 0.1953 - val_loss: 3.8749 - val_accuracy: 0.2904\n","Epoch 3/3\n","4/4 [==============================] - 5s 2s/step - loss: 3.7210 - accuracy: 0.3828 - val_loss: 3.6017 - val_accuracy: 0.4386\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 13/35 [13:48<22:32, 61.47s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b2_notop.h5\n","35840000/35839040 [==============================] - 1s 0us/step\n","35848192/35839040 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 19s 3s/step - loss: 4.3437 - accuracy: 0.1172 - val_loss: 4.1681 - val_accuracy: 0.1754\n","Epoch 2/3\n","4/4 [==============================] - 5s 2s/step - loss: 3.9342 - accuracy: 0.3047 - val_loss: 3.8309 - val_accuracy: 0.3236\n","Epoch 3/3\n","4/4 [==============================] - 5s 2s/step - loss: 3.6970 - accuracy: 0.3984 - val_loss: 3.5447 - val_accuracy: 0.4756\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|████      | 14/35 [14:23<18:44, 53.55s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n","52609024/52606240 [==============================] - 1s 0us/step\n","52617216/52606240 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 23s 3s/step - loss: 4.4029 - accuracy: 0.1094 - val_loss: 4.0946 - val_accuracy: 0.2437\n","Epoch 2/3\n","4/4 [==============================] - 6s 2s/step - loss: 3.9433 - accuracy: 0.3125 - val_loss: 3.7763 - val_accuracy: 0.3684\n","Epoch 3/3\n","4/4 [==============================] - 6s 2s/step - loss: 3.7098 - accuracy: 0.3594 - val_loss: 3.4871 - val_accuracy: 0.5029\n"]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 15/35 [15:06<16:47, 50.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n","473178112/473176280 [==============================] - 6s 0us/step\n","473186304/473176280 [==============================] - 6s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 61s 9s/step - loss: 4.4387 - accuracy: 0.0859 - val_loss: 4.2106 - val_accuracy: 0.2865\n","Epoch 2/3\n","4/4 [==============================] - 19s 6s/step - loss: 4.0169 - accuracy: 0.3672 - val_loss: 3.9742 - val_accuracy: 0.4055\n","Epoch 3/3\n","4/4 [==============================] - 19s 6s/step - loss: 3.8650 - accuracy: 0.4453 - val_loss: 3.7461 - val_accuracy: 0.5224\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▌     | 16/35 [17:18<23:43, 74.94s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-m_notop.h5\n","214204416/214201816 [==============================] - 3s 0us/step\n","214212608/214201816 [==============================] - 3s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 43s 6s/step - loss: 4.3093 - accuracy: 0.2031 - val_loss: 4.1983 - val_accuracy: 0.2242\n","Epoch 2/3\n","4/4 [==============================] - 11s 4s/step - loss: 4.1139 - accuracy: 0.3125 - val_loss: 3.9316 - val_accuracy: 0.3548\n","Epoch 3/3\n","4/4 [==============================] - 11s 4s/step - loss: 3.8468 - accuracy: 0.3984 - val_loss: 3.7189 - val_accuracy: 0.5127\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▊     | 17/35 [18:36<22:46, 75.90s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n","82427904/82420632 [==============================] - 1s 0us/step\n","82436096/82420632 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 27s 4s/step - loss: 4.3149 - accuracy: 0.1406 - val_loss: 4.1370 - val_accuracy: 0.2534\n","Epoch 2/3\n","4/4 [==============================] - 7s 2s/step - loss: 4.0004 - accuracy: 0.3594 - val_loss: 3.8386 - val_accuracy: 0.4308\n","Epoch 3/3\n","4/4 [==============================] - 7s 2s/step - loss: 3.5664 - accuracy: 0.5625 - val_loss: 3.5820 - val_accuracy: 0.5107\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████▏    | 18/35 [19:39<20:25, 72.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","219062272/219055592 [==============================] - 5s 0us/step\n","219070464/219055592 [==============================] - 5s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 31s 5s/step - loss: 833.0455 - accuracy: 0.0000e+00 - val_loss: 1204.2319 - val_accuracy: 0.0195\n","Epoch 2/3\n","4/4 [==============================] - 10s 3s/step - loss: 1082.4758 - accuracy: 0.0000e+00 - val_loss: 892.1372 - val_accuracy: 0.0136\n","Epoch 3/3\n","4/4 [==============================] - 10s 3s/step - loss: 913.4073 - accuracy: 0.0234 - val_loss: 861.6528 - val_accuracy: 0.0136\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 19/35 [20:47<18:53, 70.85s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n","87924736/87910968 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 15s 2s/step - loss: 70.7498 - accuracy: 0.0156 - val_loss: 69.7696 - val_accuracy: 0.0136\n","Epoch 2/3\n","4/4 [==============================] - 5s 2s/step - loss: 72.8312 - accuracy: 0.0078 - val_loss: 71.5621 - val_accuracy: 0.0136\n","Epoch 3/3\n","4/4 [==============================] - 5s 2s/step - loss: 64.3568 - accuracy: 0.0078 - val_loss: 61.8571 - val_accuracy: 0.0195\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 20/35 [21:21<14:57, 59.82s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n","17227776/17225924 [==============================] - 0s 0us/step\n","17235968/17225924 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 8s 2s/step - loss: 5.3737 - accuracy: 0.0312 - val_loss: 5.1800 - val_accuracy: 0.0039\n","Epoch 2/3\n","4/4 [==============================] - 4s 1s/step - loss: 5.0981 - accuracy: 0.0234 - val_loss: 4.9286 - val_accuracy: 0.0156\n","Epoch 3/3\n","4/4 [==============================] - 4s 1s/step - loss: 4.9128 - accuracy: 0.0312 - val_loss: 4.7788 - val_accuracy: 0.0253\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|██████    | 21/35 [21:45<11:26, 49.03s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","9420800/9406464 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 10s 2s/step - loss: 5.1363 - accuracy: 0.0156 - val_loss: 5.1376 - val_accuracy: 0.0136\n","Epoch 2/3\n","4/4 [==============================] - 4s 1s/step - loss: 5.1862 - accuracy: 0.0078 - val_loss: 4.9469 - val_accuracy: 0.0078\n","Epoch 3/3\n","4/4 [==============================] - 4s 1s/step - loss: 4.8554 - accuracy: 0.0078 - val_loss: 4.7819 - val_accuracy: 0.0214\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 22/35 [22:06<08:45, 40.42s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n","12689408/12683000 [==============================] - 0s 0us/step\n","12697600/12683000 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 12s 2s/step - loss: 5.0373 - accuracy: 0.0234 - val_loss: 4.9837 - val_accuracy: 0.0487\n","Epoch 2/3\n","4/4 [==============================] - 4s 1s/step - loss: 4.6120 - accuracy: 0.0547 - val_loss: 4.4447 - val_accuracy: 0.0819\n","Epoch 3/3\n","4/4 [==============================] - 4s 1s/step - loss: 4.2633 - accuracy: 0.0625 - val_loss: 3.9746 - val_accuracy: 0.1481\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 23/35 [22:33<07:19, 36.64s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n","4341760/4334752 [==============================] - 0s 0us/step\n","4349952/4334752 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 10s 2s/step - loss: 5.1121 - accuracy: 0.0000e+00 - val_loss: 4.9513 - val_accuracy: 0.0195\n","Epoch 2/3\n","4/4 [==============================] - 3s 1s/step - loss: 4.8690 - accuracy: 0.0078 - val_loss: 4.6294 - val_accuracy: 0.0351\n","Epoch 3/3\n","4/4 [==============================] - 4s 1s/step - loss: 4.3846 - accuracy: 0.0859 - val_loss: 4.4256 - val_accuracy: 0.0643\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▊   | 24/35 [22:53<05:46, 31.53s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n","343613440/343610240 [==============================] - 6s 0us/step\n","343621632/343610240 [==============================] - 6s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 81s 17s/step - loss: 5.4563 - accuracy: 0.0156 - val_loss: 5.6724 - val_accuracy: 0.0078\n","Epoch 2/3\n","4/4 [==============================] - 44s 14s/step - loss: 5.3668 - accuracy: 0.0078 - val_loss: 5.1578 - val_accuracy: 0.0078\n","Epoch 3/3\n","4/4 [==============================] - 44s 14s/step - loss: 4.9807 - accuracy: 0.0078 - val_loss: 5.0243 - val_accuracy: 0.0351\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████▏  | 25/35 [27:00<16:00, 96.09s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n","19996672/19993432 [==============================] - 0s 0us/step\n","20004864/19993432 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 28s 3s/step - loss: 13.6086 - accuracy: 0.0000e+00 - val_loss: 13.5575 - val_accuracy: 0.0078\n","Epoch 2/3\n","4/4 [==============================] - 5s 2s/step - loss: 12.1537 - accuracy: 0.0000e+00 - val_loss: 11.8710 - val_accuracy: 0.0039\n","Epoch 3/3\n","4/4 [==============================] - 5s 2s/step - loss: 10.9076 - accuracy: 0.0078 - val_loss: 10.4808 - val_accuracy: 0.0097\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 26/35 [28:06<13:03, 87.10s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n","171450368/171446536 [==============================] - 3s 0us/step\n","171458560/171446536 [==============================] - 3s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 21s 4s/step - loss: 5.9241 - accuracy: 0.0234 - val_loss: 5.6410 - val_accuracy: 0.0468\n","Epoch 2/3\n","4/4 [==============================] - 9s 3s/step - loss: 5.0572 - accuracy: 0.1094 - val_loss: 4.6610 - val_accuracy: 0.0741\n","Epoch 3/3\n","4/4 [==============================] - 9s 3s/step - loss: 4.1657 - accuracy: 0.1406 - val_loss: 4.0779 - val_accuracy: 0.1365\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 27/35 [29:04<10:26, 78.32s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","171319296/171317808 [==============================] - 3s 0us/step\n","171327488/171317808 [==============================] - 3s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 20s 3s/step - loss: 521.4638 - accuracy: 0.0078 - val_loss: 574.4836 - val_accuracy: 0.0078\n","Epoch 2/3\n","4/4 [==============================] - 8s 3s/step - loss: 502.4236 - accuracy: 0.0000e+00 - val_loss: 466.1215 - val_accuracy: 0.0078\n","Epoch 3/3\n","4/4 [==============================] - 8s 3s/step - loss: 426.7398 - accuracy: 0.0078 - val_loss: 444.5117 - val_accuracy: 0.0058\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|████████  | 28/35 [29:59<08:20, 71.46s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n","234700800/234698864 [==============================] - 4s 0us/step\n","234708992/234698864 [==============================] - 4s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 30s 5s/step - loss: 6.4172 - accuracy: 0.0234 - val_loss: 5.3378 - val_accuracy: 0.0175\n","Epoch 2/3\n","4/4 [==============================] - 12s 4s/step - loss: 4.8784 - accuracy: 0.0938 - val_loss: 4.5447 - val_accuracy: 0.0819\n","Epoch 3/3\n","4/4 [==============================] - 12s 4s/step - loss: 4.2252 - accuracy: 0.1562 - val_loss: 4.0152 - val_accuracy: 0.1501\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 29/35 [31:04<06:56, 69.49s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","234553344/234545216 [==============================] - 3s 0us/step\n","234561536/234545216 [==============================] - 3s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 27s 5s/step - loss: 1074.7341 - accuracy: 0.0078 - val_loss: 1235.8333 - val_accuracy: 0.0097\n","Epoch 2/3\n","4/4 [==============================] - 11s 4s/step - loss: 1268.2236 - accuracy: 0.0078 - val_loss: 1073.0541 - val_accuracy: 0.0117\n","Epoch 3/3\n","4/4 [==============================] - 12s 4s/step - loss: 1037.6833 - accuracy: 0.0000e+00 - val_loss: 1102.7672 - val_accuracy: 0.0058\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 30/35 [32:04<05:33, 66.65s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n","94781440/94765736 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 12s 2s/step - loss: 6.1619 - accuracy: 0.0234 - val_loss: 5.4413 - val_accuracy: 0.0429\n","Epoch 2/3\n","4/4 [==============================] - 6s 2s/step - loss: 5.2212 - accuracy: 0.0234 - val_loss: 4.8117 - val_accuracy: 0.0468\n","Epoch 3/3\n","4/4 [==============================] - 6s 2s/step - loss: 4.5026 - accuracy: 0.1250 - val_loss: 4.2242 - val_accuracy: 0.0955\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▊ | 31/35 [32:32<03:39, 54.90s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94674944/94668760 [==============================] - 1s 0us/step\n","94683136/94668760 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 12s 2s/step - loss: 252.1385 - accuracy: 0.0234 - val_loss: 230.5945 - val_accuracy: 0.0214\n","Epoch 2/3\n","4/4 [==============================] - 6s 2s/step - loss: 215.5119 - accuracy: 0.0078 - val_loss: 189.6143 - val_accuracy: 0.0097\n","Epoch 3/3\n","4/4 [==============================] - 6s 2s/step - loss: 190.3960 - accuracy: 0.0078 - val_loss: 169.6230 - val_accuracy: 0.0097\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████▏| 32/35 [32:59<02:19, 46.56s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","58900480/58889256 [==============================] - 0s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 14s 3s/step - loss: 18.7070 - accuracy: 0.0000e+00 - val_loss: 16.6150 - val_accuracy: 0.0273\n","Epoch 2/3\n","4/4 [==============================] - 7s 2s/step - loss: 16.2681 - accuracy: 0.0312 - val_loss: 14.7153 - val_accuracy: 0.0370\n","Epoch 3/3\n","4/4 [==============================] - 7s 2s/step - loss: 13.1577 - accuracy: 0.0234 - val_loss: 13.4812 - val_accuracy: 0.0351\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 33/35 [33:41<01:30, 45.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 1s 0us/step\n","80150528/80134624 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 11s 3s/step - loss: 18.3094 - accuracy: 0.0078 - val_loss: 17.2878 - val_accuracy: 0.0175\n","Epoch 2/3\n","4/4 [==============================] - 9s 3s/step - loss: 14.9997 - accuracy: 0.0312 - val_loss: 14.8619 - val_accuracy: 0.0331\n","Epoch 3/3\n","4/4 [==============================] - 8s 3s/step - loss: 14.7785 - accuracy: 0.0156 - val_loss: 13.6542 - val_accuracy: 0.0370\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 34/35 [34:25<00:44, 44.77s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","83697664/83683744 [==============================] - 1s 0us/step\n","Epoch 1/3\n","4/4 [==============================] - 18s 3s/step - loss: 52.2729 - accuracy: 0.0078 - val_loss: 36.1858 - val_accuracy: 0.0136\n","Epoch 2/3\n","4/4 [==============================] - 8s 2s/step - loss: 33.8044 - accuracy: 0.0000e+00 - val_loss: 28.4736 - val_accuracy: 0.0156\n","Epoch 3/3\n","4/4 [==============================] - 8s 3s/step - loss: 30.0784 - accuracy: 0.0078 - val_loss: 23.5044 - val_accuracy: 0.0117\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 35/35 [35:01<00:00, 60.05s/it]\n"]}],"source":["# Loop over each model available in Keras\n","model_benchmarks = {'model_name': [], 'num_model_params': [], 'validation_accuracy': []}\n","\n","for model_name, model in tqdm(model_dictionary.items()):\n","    # Special handling for \"NASNetLarge\" since it requires input images with size (331,331)\n","    if 'NASNetLarge' in model_name:\n","        input_shape=(331,331,3)\n","        train_processed = train_processed_331\n","        validation_processed = validation_processed_331\n","    else:\n","        input_shape=(224,224,3)\n","        train_processed = train_processed_224\n","        validation_processed = validation_processed_224\n","        \n","    # load the pre-trained model with global average pooling as the last layer and freeze the model weights\n","    pre_trained_model = model(include_top=False, pooling='avg', input_shape=input_shape)\n","    pre_trained_model.trainable = False\n","    \n","    # custom modifications on top of pre-trained model and fit\n","    clf_model = tf.keras.models.Sequential()\n","    clf_model.add(pre_trained_model)\n","    # clf_model.add(tf.keras.layers.BatchNormalization())\n","    # clf_model.add(Dropout(rate=.45))\n","    clf_model.add(tf.keras.layers.Dense(90, activation='softmax'))\n","    clf_model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    history = clf_model.fit(train_processed, epochs=3, validation_data=validation_processed, steps_per_epoch=num_iterations)\n","\n","    # Calculate all relevant metrics\n","    model_benchmarks['model_name'].append(model_name)\n","    model_benchmarks['num_model_params'].append(pre_trained_model.count_params())\n","    model_benchmarks['validation_accuracy'].append(history.history['val_accuracy'][-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zPVCAR11S0KN","outputId":"127ca3de-f5f8-4db5-ab6d-5cab861c9b7d"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e1cf3e50-d255-4740-9fe3-0791b512f63e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model_name</th>\n","      <th>num_model_params</th>\n","      <th>validation_accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>EfficientNetB7</td>\n","      <td>64097687</td>\n","      <td>0.575049</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>EfficientNetB6</td>\n","      <td>40960143</td>\n","      <td>0.561404</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>EfficientNetB5</td>\n","      <td>28513527</td>\n","      <td>0.526316</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>EfficientNetV2L</td>\n","      <td>117746848</td>\n","      <td>0.522417</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>EfficientNetV2M</td>\n","      <td>53150388</td>\n","      <td>0.512671</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>EfficientNetV2S</td>\n","      <td>20331360</td>\n","      <td>0.510721</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>EfficientNetV2B3</td>\n","      <td>12930622</td>\n","      <td>0.502924</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>EfficientNetV2B2</td>\n","      <td>8769374</td>\n","      <td>0.475634</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>EfficientNetV2B1</td>\n","      <td>6931124</td>\n","      <td>0.438596</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>EfficientNetB3</td>\n","      <td>10783535</td>\n","      <td>0.434698</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>EfficientNetV2B0</td>\n","      <td>5919312</td>\n","      <td>0.424951</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>EfficientNetB4</td>\n","      <td>17673823</td>\n","      <td>0.407407</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>EfficientNetB2</td>\n","      <td>7768569</td>\n","      <td>0.389864</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EfficientNetB1</td>\n","      <td>6575239</td>\n","      <td>0.356725</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EfficientNetB0</td>\n","      <td>4049571</td>\n","      <td>0.298246</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>ResNet152</td>\n","      <td>58370944</td>\n","      <td>0.150097</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>MobileNetV3Large</td>\n","      <td>2996352</td>\n","      <td>0.148148</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>ResNet101</td>\n","      <td>42658176</td>\n","      <td>0.136452</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>ResNet50</td>\n","      <td>23587712</td>\n","      <td>0.095517</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>MobileNetV3Small</td>\n","      <td>939120</td>\n","      <td>0.064327</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>VGG19</td>\n","      <td>20024384</td>\n","      <td>0.037037</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>NASNetLarge</td>\n","      <td>84916818</td>\n","      <td>0.035088</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>VGG16</td>\n","      <td>14714688</td>\n","      <td>0.035088</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>MobileNet</td>\n","      <td>3228864</td>\n","      <td>0.025341</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>MobileNetV2</td>\n","      <td>2257984</td>\n","      <td>0.021442</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>InceptionV3</td>\n","      <td>21802784</td>\n","      <td>0.019493</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DenseNet169</td>\n","      <td>12642880</td>\n","      <td>0.015595</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DenseNet201</td>\n","      <td>18321984</td>\n","      <td>0.013645</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>InceptionResNetV2</td>\n","      <td>54336736</td>\n","      <td>0.013645</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>DenseNet121</td>\n","      <td>7037504</td>\n","      <td>0.011696</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Xception</td>\n","      <td>20861480</td>\n","      <td>0.011696</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>ResNet50V2</td>\n","      <td>23564800</td>\n","      <td>0.009747</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>NASNetMobile</td>\n","      <td>4269716</td>\n","      <td>0.009747</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>ResNet152V2</td>\n","      <td>58331648</td>\n","      <td>0.005848</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>ResNet101V2</td>\n","      <td>42626560</td>\n","      <td>0.005848</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1cf3e50-d255-4740-9fe3-0791b512f63e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1cf3e50-d255-4740-9fe3-0791b512f63e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1cf3e50-d255-4740-9fe3-0791b512f63e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           model_name  num_model_params  validation_accuracy\n","10     EfficientNetB7          64097687             0.575049\n","9      EfficientNetB6          40960143             0.561404\n","8      EfficientNetB5          28513527             0.526316\n","15    EfficientNetV2L         117746848             0.522417\n","16    EfficientNetV2M          53150388             0.512671\n","17    EfficientNetV2S          20331360             0.510721\n","14   EfficientNetV2B3          12930622             0.502924\n","13   EfficientNetV2B2           8769374             0.475634\n","12   EfficientNetV2B1           6931124             0.438596\n","6      EfficientNetB3          10783535             0.434698\n","11   EfficientNetV2B0           5919312             0.424951\n","7      EfficientNetB4          17673823             0.407407\n","5      EfficientNetB2           7768569             0.389864\n","4      EfficientNetB1           6575239             0.356725\n","3      EfficientNetB0           4049571             0.298246\n","28          ResNet152          58370944             0.150097\n","22   MobileNetV3Large           2996352             0.148148\n","26          ResNet101          42658176             0.136452\n","30           ResNet50          23587712             0.095517\n","23   MobileNetV3Small            939120             0.064327\n","33              VGG19          20024384             0.037037\n","24        NASNetLarge          84916818             0.035088\n","32              VGG16          14714688             0.035088\n","20          MobileNet           3228864             0.025341\n","21        MobileNetV2           2257984             0.021442\n","19        InceptionV3          21802784             0.019493\n","1         DenseNet169          12642880             0.015595\n","2         DenseNet201          18321984             0.013645\n","18  InceptionResNetV2          54336736             0.013645\n","0         DenseNet121           7037504             0.011696\n","34           Xception          20861480             0.011696\n","31         ResNet50V2          23564800             0.009747\n","25       NASNetMobile           4269716             0.009747\n","29        ResNet152V2          58331648             0.005848\n","27        ResNet101V2          42626560             0.005848"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Convert Results to DataFrame for easy viewing\n","benchmark_df = pd.DataFrame(model_benchmarks)\n","\n","# sort in ascending order of num_model_params column\n","benchmark_df.sort_values('val_loss', inplace=True, ascending=False)\n","\n","benchmark_df"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Choosing_pretrained_model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"0cfdd3b0dffe2ad7fcbc64f5f93deae5239b8f311e6cb7a499fa34ebd238a891"}}},"nbformat":4,"nbformat_minor":0}
