{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DpdVFQy7Ww1r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_datasets\n",
            "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
            "     ---------------------------------------- 4.3/4.3 MB 4.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_datasets) (3.17.3)\n",
            "Collecting dill\n",
            "  Using cached dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "Requirement already satisfied: termcolor in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: six in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_datasets) (1.16.0)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: absl-py in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Collecting etils[epath]\n",
            "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
            "     ---------------------------------------- 98.1/98.1 kB 1.1 MB/s eta 0:00:00\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n",
            "     -------------------------------------- 51.0/51.0 kB 647.2 kB/s eta 0:00:00\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_datasets) (2.27.1)\n",
            "Collecting promise\n",
            "  Using cached promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: numpy in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_datasets) (1.22.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_datasets) (4.64.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.11)\n",
            "Collecting importlib_resources\n",
            "  Downloading importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: zipp in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from etils[epath]->tensorflow_datasets) (3.8.0)\n",
            "Collecting googleapis-common-protos<2,>=1.52.0\n",
            "  Using cached googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.4)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\rayst\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from etils[epath]->tensorflow_datasets) (4.2.0)\n",
            "Building wheels for collected packages: promise\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): still running...\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=379a79c2ad66976f4e50ad2c23a105c4027e04a4590a00e4ad097669c00cc764\n",
            "  Stored in directory: c:\\users\\rayst\\appdata\\local\\pip\\cache\\wheels\\e1\\e8\\83\\ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
            "Successfully built promise\n",
            "Installing collected packages: toml, promise, importlib_resources, etils, dill, googleapis-common-protos, tensorflow-metadata, tensorflow_datasets\n",
            "Successfully installed dill-0.3.5.1 etils-0.6.0 googleapis-common-protos-1.56.3 importlib_resources-5.8.0 promise-2.3 tensorflow-metadata-1.9.0 tensorflow_datasets-4.6.0 toml-0.10.2\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import cv2\n",
        "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "import shutil\n",
        "import imghdr\n",
        "import Augmentor\n",
        "# Set batch size for training and validation\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1ipx0ijW1Di",
        "outputId": "566d2bf8-a260-4337-d51e-20467ea294e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting : 100%|██████████| 1/1 [00:06<00:00,  6.76s/it]\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(str(Path(os.getcwd()).parents[1]))\n",
        "from Helper_Functions import common_utils, classification_utils\n",
        "directory_to_extract_to = os.getcwd()\n",
        "\n",
        "common_utils.load_data_from_one_drive(directory_to_extract_to, \"classification_paths\", \"mit_indoor_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "common_utils.load_data_from_one_drive(directory_to_extract_to, \"classification_paths\", \"mit_indoor_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEdQHy3cXDnH",
        "outputId": "bb6bb356-adba-4d18-853a-fd447f0b5d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dentaloffice', 'hairsalon', 'waitingroom']\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "data_dir = 'content/cleaned_indoorCVPR_09_final'\n",
        "Name = os.listdir(data_dir)\n",
        "print(Name)\n",
        "print(len(Name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbu4kFv2OMSB"
      },
      "outputs": [],
      "source": [
        "## Clean dataset\n",
        "# os.makedirs('/content/cleaned_indoorCVPR_09')\n",
        "\n",
        "# for i in Name:\n",
        "#   source = '/content/indoorCVPR_09/Images/' + i\n",
        "#   allFileNames = os.listdir(source)\n",
        "#   all_FileNames = [source+'/' + name for name in allFileNames]\n",
        "\n",
        "#   os.makedirs('/content/cleaned_indoorCVPR_09/'+i)\n",
        "#   for name in all_FileNames:\n",
        "#     if imghdr.what(name) == 'jpeg': # Added this line as model training was giving an error as different types of images were present in the dataset\n",
        "#       shutil.copy(name, '/content/cleaned_indoorCVPR_09/' + i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC70FDxg5XEA"
      },
      "outputs": [],
      "source": [
        "# !zip -r \"/content/drive/MyDrive/Data/cleaned_indoorCVPR_09_final.zip\" \"/content/content/cleaned_indoorCVPR_09_final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xiI4MYVJNo_u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "\n",
        "classes = Name\n",
        "\n",
        "for i in Name:\n",
        "  os.makedirs('train/' + i)\n",
        "  os.makedirs('test/' + i)\n",
        "  source = 'content/cleaned_indoorCVPR_09_final/' + i\n",
        "  #source = '/improvement/cleaned_indoorCVPR_09_final/' + i\n",
        "  allFileNames = os.listdir(source)\n",
        "  np.random.shuffle(allFileNames)\n",
        "\n",
        "  test_ratio = 0.05\n",
        "  \n",
        "  train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
        "                                                      [int(len(allFileNames)* (1 - test_ratio))])\n",
        "\n",
        "  train_FileNames = [source+'/'+ name for name in train_FileNames.tolist()]\n",
        "  test_FileNames = [source+'/' + name for name in test_FileNames.tolist()]\n",
        "\n",
        "\n",
        "  for name in train_FileNames:\n",
        "    shutil.copy(name, 'train/' + i)\n",
        "\n",
        "  for name in test_FileNames:\n",
        "    shutil.copy(name, 'test/' + i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzUKeSIBoyqr"
      },
      "outputs": [],
      "source": [
        "## Used to recursive delete files inside specified folder\n",
        "# import shutil\n",
        "# shutil.rmtree('/content/train')\n",
        "# shutil.rmtree('/content/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQagPmcBXIWT",
        "outputId": "d8eead3d-0b0b-424c-b86f-4387f6c88fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15650 files belonging to 67 classes.\n",
            "Using 14085 files for training.\n",
            "Found 15650 files belonging to 67 classes.\n",
            "Using 1565 files for validation.\n"
          ]
        }
      ],
      "source": [
        "image_size = (224,224)\n",
        "train_dir = 'train'\n",
        "train_dataset  = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n",
        "                                                                    batch_size = 32,\n",
        "                                                                    image_size = image_size,\n",
        "                                                                    shuffle = True, \n",
        "                                                                    seed = 505,\n",
        "                                                                    validation_split=0.1,\n",
        "                                                                    subset = \"training\")\n",
        "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n",
        "                                                                    batch_size = 32,\n",
        "                                                                    image_size = image_size,\n",
        "                                                                    shuffle = True, \n",
        "                                                                    seed = 505,\n",
        "                                                                    validation_split=0.1,\n",
        "                                                                    subset = \"validation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdo9A6RNX4jj",
        "outputId": "cb9dbbfa-4ea8-4216-e245-4f2f9aebcea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b2_notop.h5\n",
            "35840000/35839040 [==============================] - 0s 0us/step\n",
            "35848192/35839040 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model=tf.keras.applications.EfficientNetV2B2(include_top=False, weights=\"imagenet\",input_shape=(256, 256, 3), pooling='max') \n",
        "\n",
        "x=base_model.output\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x = Dense(224, activation='relu')(x)\n",
        "x=Dropout(rate=.5)(x)        \n",
        "output=Dense(len(Name), activation='softmax')(x)\n",
        "\n",
        "model=Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(Adamax(learning_rate=.001), loss='sparse_categorical_crossentropy', metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxoYISr9se6Z",
        "outputId": "4e8f5a4a-9b34-4567-d4d9-7466d63e0990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-decc1719-6ab1-3983-e33b-1d2ec4f90ab4)\n"
          ]
        }
      ],
      "source": [
        "#!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YD0pHpO2gUw"
      },
      "outputs": [],
      "source": [
        "## Code to remove images\n",
        "# import os\n",
        "\n",
        "# for cls in needs_improvement_lst:\n",
        "#   c=0\n",
        "#   cpath = f'/content/content/cleaned_indoorCVPR_09_final/{cls}'\n",
        "#   for file in os.listdir(cpath):\n",
        "#         os.remove(os.path.join(cpath, file)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQRiJspdYGEj",
        "outputId": "a9199969-1b4f-47d0-ae05-ae639ab6014b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "441/441 [==============================] - 319s 688ms/step - loss: 0.2929 - accuracy: 0.9261 - val_loss: 0.1456 - val_accuracy: 0.9642\n",
            "Epoch 2/10\n",
            "441/441 [==============================] - 298s 674ms/step - loss: 0.1694 - accuracy: 0.9524 - val_loss: 0.1187 - val_accuracy: 0.9681\n",
            "Epoch 3/10\n",
            "441/441 [==============================] - 298s 676ms/step - loss: 0.1157 - accuracy: 0.9676 - val_loss: 0.1067 - val_accuracy: 0.9712\n",
            "Epoch 4/10\n",
            "441/441 [==============================] - 298s 675ms/step - loss: 0.0897 - accuracy: 0.9733 - val_loss: 0.0987 - val_accuracy: 0.9770\n",
            "Epoch 5/10\n",
            "441/441 [==============================] - 301s 682ms/step - loss: 0.0686 - accuracy: 0.9791 - val_loss: 0.0954 - val_accuracy: 0.9776\n",
            "Epoch 6/10\n",
            "441/441 [==============================] - 301s 681ms/step - loss: 0.0588 - accuracy: 0.9827 - val_loss: 0.0948 - val_accuracy: 0.9770\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(x=train_dataset,  epochs=10, verbose=1,  validation_data=validation_dataset,\n",
        "               callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WJuIcRS8JXmS"
      },
      "outputs": [],
      "source": [
        "# model.save(\"best_till_now_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "B8SKWTwBPCf3"
      },
      "outputs": [],
      "source": [
        "## Load already trained model\n",
        "model = tf.keras.models.load_model('my_model_latest.h5')\n",
        "model.compile(Adamax(learning_rate=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rikAzGJRYU6r"
      },
      "outputs": [],
      "source": [
        "Name.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yV1Ji097YbVa"
      },
      "outputs": [],
      "source": [
        "def predict (img,model):\n",
        "    img = cv2.resize(img,dsize=image_size,interpolation=cv2.INTER_CUBIC)\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    prediction = model.predict(img)\n",
        "    cname =np.argmax(prediction)\n",
        "    category = Name[cname]    \n",
        "    return category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP3R9yJDYmVb",
        "outputId": "0abd30e5-851e-4b56-c087-e9cfff636ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['airport_inside', 'artstudio', 'auditorium', 'bakery', 'bar', 'bathroom', 'bedroom', 'bookstore', 'bowling', 'buffet', 'casino', 'children_room', 'church_inside', 'classroom', 'cloister', 'closet', 'clothingstore', 'computerroom', 'concert_hall', 'corridor', 'deli', 'dentaloffice', 'dining_room', 'elevator', 'fastfood_restaurant', 'florist', 'gameroom', 'garage', 'greenhouse', 'grocerystore', 'gym', 'hairsalon', 'hospitalroom', 'inside_bus', 'inside_subway', 'jewelleryshop', 'kindergarden', 'kitchen', 'laboratorywet', 'laundromat', 'library', 'livingroom', 'lobby', 'locker_room', 'mall', 'meeting_room', 'movietheater', 'museum', 'nursery', 'office', 'operating_room', 'pantry', 'poolinside', 'prisoncell', 'restaurant', 'restaurant_kitchen', 'shoeshop', 'stairscase', 'studiomusic', 'subway', 'toystore', 'trainstation', 'tv_studio', 'videostore', 'waitingroom', 'warehouse', 'winecellar']\n"
          ]
        }
      ],
      "source": [
        "print(Name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lPK5OE_RYsob"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o4VzGDyYuud",
        "outputId": "ce93bc1f-e78c-4988-af2a-ffaaf265fffa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 3/67 [00:10<03:22,  3.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auditorium : 83.33333333333334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 4/67 [00:12<03:04,  2.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bakery : 63.33333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 5/67 [00:15<02:51,  2.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bar : 80.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 8/67 [00:23<02:38,  2.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bookstore : 80.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 10/67 [00:28<02:28,  2.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "buffet : 46.666666666666664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 19/67 [00:52<02:11,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "concert_hall : 70.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 21/67 [00:57<02:01,  2.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deli : 56.666666666666664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 25/67 [01:07<01:49,  2.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fastfood_restaurant : 73.33333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 30/67 [01:20<01:36,  2.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grocerystore : 80.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 42/67 [01:52<01:04,  2.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "livingroom : 76.66666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 43/67 [01:55<01:02,  2.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lobby : 83.33333333333334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 45/67 [02:00<00:58,  2.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mall : 70.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 48/67 [02:08<00:49,  2.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "museum : 76.66666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 53/67 [02:21<00:36,  2.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "poolinside : 76.66666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 55/67 [02:26<00:30,  2.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "restaurant : 73.33333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▎ | 56/67 [02:29<00:28,  2.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "restaurant_kitchen : 80.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 67/67 [02:58<00:00,  2.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winecellar : 76.66666666666667\n",
            "Accuracy : 89.25373134328358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "correct_pred = 0\n",
        "total_test_images = 0\n",
        "#imprv = []\n",
        "for i in tqdm(Name):\n",
        "  images = load_images_from_folder(f\"test/{i}/\")\n",
        "  total_test_images+=len(images)\n",
        "  #c=0\n",
        "  for image in images:\n",
        "    pred = predict(image, model)\n",
        "    #print(\"predicted : \",pred, \" Actual : \",i)\n",
        "    if(pred == i):\n",
        "      #c+=1\n",
        "      correct_pred+=1\n",
        "  # if (c/len(images))*100 <85:\n",
        "  #   imprv.append(i)\n",
        "  #   print(f'{i} : {(c/len(images))*100}')\n",
        "\n",
        "print(f\"Accuracy : {(correct_pred/total_test_images)*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_uSRdBJC0sB"
      },
      "outputs": [],
      "source": [
        "## Noticed if we resize and then data augment, data augmentation is faster\n",
        "import PIL\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "for files in tqdm(needs_improvement_lst):\n",
        "  cpath = f\"content/cleaned_indoorCVPR_09_final/{files}\"\n",
        "  for img in os.listdir(cpath):\n",
        "    f1 = os.path.join(cpath, img)\n",
        "    img = Image.open(f1)\n",
        "    img = img.resize((256,256))\n",
        "    img.save(f1)\n",
        "\n",
        "## Code to data augment and create more images for needs_improvement_lst\n",
        "for i in needs_improvement_lst:\n",
        "  #os.makedirs(f'/improvement_1/cleaned_indoorCVPR_09_final/{i}')\n",
        "  p = Augmentor.Pipeline(f\"content/cleaned_indoorCVPR_09_final/{i}\", output_directory=f'content/cleaned_indoorCVPR_09_final/{i}')\n",
        "  p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=20)\n",
        "  p.zoom(probability=0.5, min_factor=1.1, max_factor=1.8)\n",
        "  p.flip_left_right(probability=0.7)\n",
        "  p.sample(466)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieE2d_Tkg5uU"
      },
      "outputs": [],
      "source": [
        "## code to check number of images in each folder/class\n",
        "for i in tqdm(Name):\n",
        "  images = load_images_from_folder(f\"train/{i}/\")\n",
        "  print(\"Class : \",i,\"\\tNumber of images : \",len(images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoT0KrT2RC5t"
      },
      "outputs": [],
      "source": [
        "## What needs to be done,\n",
        "\n",
        "## 1) Redo random search CV code is below.\n",
        "## 2) Increase image distribution for imprv lst of images. (best_till_now_model.h5 is the best model we have wit 89.5% accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mZc3V1wRXtX"
      },
      "outputs": [],
      "source": [
        "## Code for randomsearchCV\n",
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.regularizers import l1_l2\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import warnings\n",
        "import PIL\n",
        "import os\n",
        "from PIL import Image\n",
        "import gc\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWh0nT9dS1aV"
      },
      "outputs": [],
      "source": [
        "for files in tqdm(Name):\n",
        "  cpath = f\"train/{files}\"\n",
        "  for img in os.listdir(cpath):\n",
        "    f1 = os.path.join(cpath, img)\n",
        "    img = Image.open(f1)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-O8_gXNS3ym"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "label = []\n",
        "Files = Name\n",
        "label_val = 0\n",
        "\n",
        "for files in tqdm(Files):\n",
        "    cpath = f\"train/{files}\"\n",
        "    for img in os.listdir(cpath):\n",
        "        image_array = cv2.imread(os.path.join(cpath, img), cv2.IMREAD_COLOR)\n",
        "        data.append(image_array)\n",
        "        label.append(label_val)\n",
        "    label_val = label_val + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RCcgxXaS6sN"
      },
      "outputs": [],
      "source": [
        "data = np.asarray(data)\n",
        "label = np.asarray(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ivo8LHyS8gt"
      },
      "outputs": [],
      "source": [
        "def create_model( nl1=1, nl2=1,  nl3=1, \n",
        "                 nn1=1000, nn2=500, nn3 = 200, lr=0.01, l1=0.01, l2=0.01,\n",
        "                act = 'relu', dropout=0):\n",
        "    '''This is a model generating function so that we can search over neural net \n",
        "    parameters and architecture'''\n",
        "    \n",
        "    opt = Adam(lr=lr)\n",
        "    #reg = l1_l2(l1=l1, l2=l2)\n",
        "                                                     \n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.applications.EfficientNetV2B2(include_top=False, weights=\"imagenet\",input_shape=(224, 224, 3), pooling='max'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    # for the firt layer we need to specify the input dimensions\n",
        "    first=True\n",
        "    for i in range(nl1):\n",
        "        if first:\n",
        "            model.add(Dense(nn1, activation=act)\n",
        "            first=False\n",
        "        else: \n",
        "            model.add(Dense(nn1, activation=act)\n",
        "        if dropout!=0:\n",
        "            model.add(Dropout(dropout))\n",
        "\n",
        "    for i in range(nl2):\n",
        "        if first:\n",
        "            model.add(Dense(nn2, activation=act)\n",
        "            first=False\n",
        "        else: \n",
        "            model.add(Dense(nn2, activation=act)\n",
        "        if dropout!=0:\n",
        "            model.add(Dropout(dropout))\n",
        "            \n",
        "    for i in range(nl3):\n",
        "        if first:\n",
        "            model.add(Dense(nn3, activation=act)\n",
        "            first=False\n",
        "        else: \n",
        "            model.add(Dense(nn3, activation=act)\n",
        "        if dropout!=0:\n",
        "            model.add(Dropout(dropout))\n",
        "            \n",
        "    model.add(Dense(67, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojz6QKOPS-z2"
      },
      "outputs": [],
      "source": [
        "model = KerasClassifier(build_fn=create_model, epochs=6, batch_size=4, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJB0DfjLTygW"
      },
      "outputs": [],
      "source": [
        "# learning algorithm parameters\n",
        "lr=[1e-2, 1e-3, 1e-4]\n",
        "\n",
        "\n",
        "# activation\n",
        "activation=['relu', 'softplus', 'softsign', 'tanh', 'selu',\n",
        "                   'elu', 'exponential', 'LeakyReLU']\n",
        "\n",
        "optimizers = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
        "\n",
        "# numbers of layers\n",
        "nl1 = [0,1,2,3]\n",
        "nl2 = [0,1,2,3]\n",
        "nl3 = [0,1,2,3]\n",
        "\n",
        "# neurons in each layer\n",
        "nn1=[256,512,1024]\n",
        "nn2=[256,512,1024]\n",
        "nn3=[256,512,1024]\n",
        "\n",
        "# dropout and regularisation\n",
        "dropout = [0.4,0.5,0.6]\n",
        "# l1 = [0, 0.01, 0.003, 0.001,0.0001]\n",
        "# l2 = [0, 0.01, 0.003, 0.001,0.0001]\n",
        "\n",
        "# dictionary summary\n",
        "param_grid = dict(\n",
        "                    nl1=nl1, nl2=nl2, nl3=nl3, nn1=nn1, nn2=nn2, nn3=nn3,\n",
        "                    act=activation, lr=lr, dropout=dropout, opt = optimizers\n",
        "                 )\n",
        "grid = RandomizedSearchCV(estimator=model, cv=KFold(3), param_distributions=param_grid, \n",
        "                          verbose=1,  n_iter=10, n_jobs=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS77G56WT0H1"
      },
      "outputs": [],
      "source": [
        "grid_result = grid.fit(data, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmOpMK2IT1zN"
      },
      "outputs": [],
      "source": [
        "print(grid_result.best_params_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MIT_indoor_classi_(1)_(1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "491087cb93853b3223ceecd3eaf02cbe146eb9b2fde0f129c3f4378ec7d95feb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
