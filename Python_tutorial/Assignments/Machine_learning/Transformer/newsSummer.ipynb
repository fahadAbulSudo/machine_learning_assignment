{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_LEN = 100\n",
    "DECODER_LEN = 20\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = BATCH_SIZE*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short  \n",
       "0  The CBI on Saturday booked four former officia...  \n",
       "1  Chief Justice JS Khehar has said the Supreme C...  \n",
       "2  At least three people were killed, including a...  \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
       "4  TV news anchor Arnab Goswami has said he was t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_excel(\"Inshorts Cleaned Data.xlsx\",engine = 'openpyxl')\n",
    "news.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = news['Short']\n",
    "summary = news['Headline']\n",
    "article = article.apply(lambda x: '<SOS> ' + x + ' <EOS>')\n",
    "summary = summary.apply(lambda x: '<SOS> ' + x + ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"&.[1-9]+;\",\" \",text)\n",
    "    return text\n",
    "article = article.apply(lambda x: preprocess(x))\n",
    "summary = summary.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'\n",
    "article_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
    "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
    "article_tokenizer.fit_on_texts(article)\n",
    "summary_tokenizer.fit_on_texts(summary)\n",
    "inputs = article_tokenizer.texts_to_sequences(article)\n",
    "targets = summary_tokenizer.texts_to_sequences(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76362 29661\n"
     ]
    }
   ],
   "source": [
    "ENCODER_VOCAB = len(article_tokenizer.word_index) + 1\n",
    "DECODER_VOCAB = len(summary_tokenizer.word_index) + 1\n",
    "print(ENCODER_VOCAB, DECODER_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\n",
    "inputs = tf.cast(inputs, dtype=tf.int64)\n",
    "targets = tf.cast(targets, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x\n",
    "\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "        \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "EPOCHS = 20\n",
    "\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "encoder_maxlen = 400\n",
    "decoder_maxlen = 75\n",
    "\n",
    "encoder_vocab_size, decoder_vocab_size = 76362, 29661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    pe_input=encoder_vocab_size, \n",
    "    pe_target=decoder_vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 4\n",
    "dropout_rate = 0.2\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        print(step)\n",
    "        print(\"he\")\n",
    "        arg1 = tf.math.rsqrt(float(step))\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'iteration:0' shape=() dtype=int64, numpy=0>\n",
      "he\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert 3.952847075210474e-06 to EagerTensor of dtype int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\Transformer\\newsSummer.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abulf/Documents/Python_tutorial/Assignments/Machine_learning/Transformer/newsSummer.ipynb#ch0000018?line=1'>2</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m CustomSchedule(d_model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abulf/Documents/Python_tutorial/Assignments/Machine_learning/Transformer/newsSummer.ipynb#ch0000018?line=2'>3</a>\u001b[0m \u001b[39m#print(learning_rate)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/abulf/Documents/Python_tutorial/Assignments/Machine_learning/Transformer/newsSummer.ipynb#ch0000018?line=3'>4</a>\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49moptimizers\u001b[39m.\u001b[39;49mAdam(learning_rate\u001b[39m=\u001b[39;49mlearning_rate, beta_1\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m, beta_2\u001b[39m=\u001b[39;49m\u001b[39m0.98\u001b[39;49m, epsilon\u001b[39m=\u001b[39;49m\u001b[39m1e-9\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\myvenv\\lib\\site-packages\\keras\\optimizers\\adam.py:116\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     87\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     88\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    103\u001b[0m ):\n\u001b[0;32m    104\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    105\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    106\u001b[0m         weight_decay\u001b[39m=\u001b[39mweight_decay,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    115\u001b[0m     )\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_learning_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_learning_rate(learning_rate)\n\u001b[0;32m    117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta_1 \u001b[39m=\u001b[39m beta_1\n\u001b[0;32m    118\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta_2 \u001b[39m=\u001b[39m beta_2\n",
      "File \u001b[1;32mc:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\myvenv\\lib\\site-packages\\keras\\optimizers\\optimizer.py:384\u001b[0m, in \u001b[0;36m_BaseOptimizer._build_learning_rate\u001b[1;34m(self, learning_rate)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39minit_scope():\n\u001b[0;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    380\u001b[0m         learning_rate, learning_rate_schedule\u001b[39m.\u001b[39mLearningRateSchedule\n\u001b[0;32m    381\u001b[0m     ):\n\u001b[0;32m    382\u001b[0m         \u001b[39m# Create a variable to hold the current learning rate.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m         current_learning_rate \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m--> 384\u001b[0m             learning_rate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterations)\n\u001b[0;32m    385\u001b[0m         )\n\u001b[0;32m    386\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_learning_rate \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mVariable(\n\u001b[0;32m    387\u001b[0m             current_learning_rate,\n\u001b[0;32m    388\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcurrent_learning_rate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    389\u001b[0m             dtype\u001b[39m=\u001b[39mcurrent_learning_rate\u001b[39m.\u001b[39mdtype,\n\u001b[0;32m    390\u001b[0m             trainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    391\u001b[0m         )\n\u001b[0;32m    392\u001b[0m         \u001b[39mreturn\u001b[39;00m learning_rate\n",
      "\u001b[1;32mc:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\Transformer\\newsSummer.ipynb Cell 20'\u001b[0m in \u001b[0;36mCustomSchedule.__call__\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abulf/Documents/Python_tutorial/Assignments/Machine_learning/Transformer/newsSummer.ipynb#ch0000017?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhe\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abulf/Documents/Python_tutorial/Assignments/Machine_learning/Transformer/newsSummer.ipynb#ch0000017?line=12'>13</a>\u001b[0m arg1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mrsqrt(\u001b[39mfloat\u001b[39m(step))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/abulf/Documents/Python_tutorial/Assignments/Machine_learning/Transformer/newsSummer.ipynb#ch0000017?line=13'>14</a>\u001b[0m arg2 \u001b[39m=\u001b[39m step \u001b[39m*\u001b[39;49m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarmup_steps \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1.5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abulf/Documents/Python_tutorial/Assignments/Machine_learning/Transformer/newsSummer.ipynb#ch0000017?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mrsqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model) \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mminimum(arg1, arg2)\n",
      "File \u001b[1;32mc:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\myvenv\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:1106\u001b[0m, in \u001b[0;36mVariable._OverloadOperator.<locals>._run_op\u001b[1;34m(a, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_op\u001b[39m(a, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1105\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor_oper(a\u001b[39m.\u001b[39mvalue(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\myvenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\myvenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:7324\u001b[0m, in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   7322\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   7323\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 7324\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m   7325\u001b[0m       _ctx, \u001b[39m\"\u001b[39m\u001b[39mMul\u001b[39m\u001b[39m\"\u001b[39m, name, x, y)\n\u001b[0;32m   7326\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   7327\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert 3.952847075210474e-06 to EagerTensor of dtype int64"
     ]
    }
   ],
   "source": [
    "#print(d_model)\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "#print(learning_rate)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('myvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f10a24a426163f4969834cd78cacbc8a505b0e39e0a52f8aaabad16331e335f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
