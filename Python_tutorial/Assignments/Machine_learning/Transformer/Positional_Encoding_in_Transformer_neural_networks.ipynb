{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abulf\\Documents\\Python_tutorial\\Assignments\\Machine_learning\\myvenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "max_sequence_length = 4\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My name is Fahad  = 4*4 matrix * (4*512) matrix = 4*512 matrix\n",
    "[1,0,0,0]\n",
    "[0,1,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
       "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
       "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
       "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
       "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
       "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
       "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
       "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
       "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
       "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
       "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
       "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
       "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
       "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
       "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
       "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
       "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
       "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
       "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
       "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
       "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
       "        504., 506., 508., 510.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_i = torch.arange(0, d_model, 2).float()\n",
    "even_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0366e+00, 1.0746e+00, 1.1140e+00, 1.1548e+00, 1.1971e+00,\n",
       "        1.2409e+00, 1.2864e+00, 1.3335e+00, 1.3824e+00, 1.4330e+00, 1.4855e+00,\n",
       "        1.5399e+00, 1.5963e+00, 1.6548e+00, 1.7154e+00, 1.7783e+00, 1.8434e+00,\n",
       "        1.9110e+00, 1.9810e+00, 2.0535e+00, 2.1288e+00, 2.2067e+00, 2.2876e+00,\n",
       "        2.3714e+00, 2.4582e+00, 2.5483e+00, 2.6416e+00, 2.7384e+00, 2.8387e+00,\n",
       "        2.9427e+00, 3.0505e+00, 3.1623e+00, 3.2781e+00, 3.3982e+00, 3.5227e+00,\n",
       "        3.6517e+00, 3.7855e+00, 3.9242e+00, 4.0679e+00, 4.2170e+00, 4.3714e+00,\n",
       "        4.5316e+00, 4.6976e+00, 4.8697e+00, 5.0481e+00, 5.2330e+00, 5.4247e+00,\n",
       "        5.6234e+00, 5.8294e+00, 6.0430e+00, 6.2643e+00, 6.4938e+00, 6.7317e+00,\n",
       "        6.9783e+00, 7.2339e+00, 7.4989e+00, 7.7737e+00, 8.0584e+00, 8.3536e+00,\n",
       "        8.6596e+00, 8.9769e+00, 9.3057e+00, 9.6466e+00, 1.0000e+01, 1.0366e+01,\n",
       "        1.0746e+01, 1.1140e+01, 1.1548e+01, 1.1971e+01, 1.2409e+01, 1.2864e+01,\n",
       "        1.3335e+01, 1.3824e+01, 1.4330e+01, 1.4855e+01, 1.5399e+01, 1.5963e+01,\n",
       "        1.6548e+01, 1.7154e+01, 1.7783e+01, 1.8434e+01, 1.9110e+01, 1.9810e+01,\n",
       "        2.0535e+01, 2.1288e+01, 2.2067e+01, 2.2876e+01, 2.3714e+01, 2.4582e+01,\n",
       "        2.5483e+01, 2.6416e+01, 2.7384e+01, 2.8387e+01, 2.9427e+01, 3.0505e+01,\n",
       "        3.1623e+01, 3.2781e+01, 3.3982e+01, 3.5227e+01, 3.6517e+01, 3.7855e+01,\n",
       "        3.9242e+01, 4.0679e+01, 4.2170e+01, 4.3714e+01, 4.5316e+01, 4.6976e+01,\n",
       "        4.8697e+01, 5.0481e+01, 5.2330e+01, 5.4247e+01, 5.6234e+01, 5.8294e+01,\n",
       "        6.0430e+01, 6.2643e+01, 6.4938e+01, 6.7317e+01, 6.9783e+01, 7.2339e+01,\n",
       "        7.4989e+01, 7.7737e+01, 8.0584e+01, 8.3536e+01, 8.6596e+01, 8.9769e+01,\n",
       "        9.3057e+01, 9.6466e+01, 1.0000e+02, 1.0366e+02, 1.0746e+02, 1.1140e+02,\n",
       "        1.1548e+02, 1.1971e+02, 1.2409e+02, 1.2864e+02, 1.3335e+02, 1.3824e+02,\n",
       "        1.4330e+02, 1.4855e+02, 1.5399e+02, 1.5963e+02, 1.6548e+02, 1.7154e+02,\n",
       "        1.7783e+02, 1.8434e+02, 1.9110e+02, 1.9810e+02, 2.0535e+02, 2.1288e+02,\n",
       "        2.2067e+02, 2.2876e+02, 2.3714e+02, 2.4582e+02, 2.5483e+02, 2.6416e+02,\n",
       "        2.7384e+02, 2.8387e+02, 2.9427e+02, 3.0505e+02, 3.1623e+02, 3.2781e+02,\n",
       "        3.3982e+02, 3.5227e+02, 3.6517e+02, 3.7855e+02, 3.9242e+02, 4.0679e+02,\n",
       "        4.2170e+02, 4.3714e+02, 4.5316e+02, 4.6976e+02, 4.8697e+02, 5.0481e+02,\n",
       "        5.2330e+02, 5.4247e+02, 5.6234e+02, 5.8294e+02, 6.0430e+02, 6.2643e+02,\n",
       "        6.4938e+02, 6.7317e+02, 6.9783e+02, 7.2339e+02, 7.4989e+02, 7.7737e+02,\n",
       "        8.0584e+02, 8.3536e+02, 8.6596e+02, 8.9769e+02, 9.3057e+02, 9.6466e+02,\n",
       "        1.0000e+03, 1.0366e+03, 1.0746e+03, 1.1140e+03, 1.1548e+03, 1.1971e+03,\n",
       "        1.2409e+03, 1.2864e+03, 1.3335e+03, 1.3824e+03, 1.4330e+03, 1.4855e+03,\n",
       "        1.5399e+03, 1.5963e+03, 1.6548e+03, 1.7154e+03, 1.7783e+03, 1.8434e+03,\n",
       "        1.9110e+03, 1.9810e+03, 2.0535e+03, 2.1288e+03, 2.2067e+03, 2.2876e+03,\n",
       "        2.3714e+03, 2.4582e+03, 2.5483e+03, 2.6416e+03, 2.7384e+03, 2.8387e+03,\n",
       "        2.9427e+03, 3.0505e+03, 3.1623e+03, 3.2781e+03, 3.3982e+03, 3.5227e+03,\n",
       "        3.6517e+03, 3.7855e+03, 3.9242e+03, 4.0679e+03, 4.2170e+03, 4.3714e+03,\n",
       "        4.5316e+03, 4.6976e+03, 4.8697e+03, 5.0481e+03, 5.2330e+03, 5.4247e+03,\n",
       "        5.6234e+03, 5.8294e+03, 6.0430e+03, 6.2643e+03, 6.4938e+03, 6.7317e+03,\n",
       "        6.9783e+03, 7.2339e+03, 7.4989e+03, 7.7737e+03, 8.0584e+03, 8.3536e+03,\n",
       "        8.6596e+03, 8.9769e+03, 9.3057e+03, 9.6466e+03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_denominator = torch.pow(10000, even_i/d_model)\n",
    "even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,   3.,   5.,   7.,   9.,  11.,  13.,  15.,  17.,  19.,  21.,  23.,\n",
       "         25.,  27.,  29.,  31.,  33.,  35.,  37.,  39.,  41.,  43.,  45.,  47.,\n",
       "         49.,  51.,  53.,  55.,  57.,  59.,  61.,  63.,  65.,  67.,  69.,  71.,\n",
       "         73.,  75.,  77.,  79.,  81.,  83.,  85.,  87.,  89.,  91.,  93.,  95.,\n",
       "         97.,  99., 101., 103., 105., 107., 109., 111., 113., 115., 117., 119.,\n",
       "        121., 123., 125., 127., 129., 131., 133., 135., 137., 139., 141., 143.,\n",
       "        145., 147., 149., 151., 153., 155., 157., 159., 161., 163., 165., 167.,\n",
       "        169., 171., 173., 175., 177., 179., 181., 183., 185., 187., 189., 191.,\n",
       "        193., 195., 197., 199., 201., 203., 205., 207., 209., 211., 213., 215.,\n",
       "        217., 219., 221., 223., 225., 227., 229., 231., 233., 235., 237., 239.,\n",
       "        241., 243., 245., 247., 249., 251., 253., 255., 257., 259., 261., 263.,\n",
       "        265., 267., 269., 271., 273., 275., 277., 279., 281., 283., 285., 287.,\n",
       "        289., 291., 293., 295., 297., 299., 301., 303., 305., 307., 309., 311.,\n",
       "        313., 315., 317., 319., 321., 323., 325., 327., 329., 331., 333., 335.,\n",
       "        337., 339., 341., 343., 345., 347., 349., 351., 353., 355., 357., 359.,\n",
       "        361., 363., 365., 367., 369., 371., 373., 375., 377., 379., 381., 383.,\n",
       "        385., 387., 389., 391., 393., 395., 397., 399., 401., 403., 405., 407.,\n",
       "        409., 411., 413., 415., 417., 419., 421., 423., 425., 427., 429., 431.,\n",
       "        433., 435., 437., 439., 441., 443., 445., 447., 449., 451., 453., 455.,\n",
       "        457., 459., 461., 463., 465., 467., 469., 471., 473., 475., 477., 479.,\n",
       "        481., 483., 485., 487., 489., 491., 493., 495., 497., 499., 501., 503.,\n",
       "        505., 507., 509., 511.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_i = torch.arange(1, d_model, 2).float()\n",
    "odd_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0366e+00, 1.0746e+00, 1.1140e+00, 1.1548e+00, 1.1971e+00,\n",
       "        1.2409e+00, 1.2864e+00, 1.3335e+00, 1.3824e+00, 1.4330e+00, 1.4855e+00,\n",
       "        1.5399e+00, 1.5963e+00, 1.6548e+00, 1.7154e+00, 1.7783e+00, 1.8434e+00,\n",
       "        1.9110e+00, 1.9810e+00, 2.0535e+00, 2.1288e+00, 2.2067e+00, 2.2876e+00,\n",
       "        2.3714e+00, 2.4582e+00, 2.5483e+00, 2.6416e+00, 2.7384e+00, 2.8387e+00,\n",
       "        2.9427e+00, 3.0505e+00, 3.1623e+00, 3.2781e+00, 3.3982e+00, 3.5227e+00,\n",
       "        3.6517e+00, 3.7855e+00, 3.9242e+00, 4.0679e+00, 4.2170e+00, 4.3714e+00,\n",
       "        4.5316e+00, 4.6976e+00, 4.8697e+00, 5.0481e+00, 5.2330e+00, 5.4247e+00,\n",
       "        5.6234e+00, 5.8294e+00, 6.0430e+00, 6.2643e+00, 6.4938e+00, 6.7317e+00,\n",
       "        6.9783e+00, 7.2339e+00, 7.4989e+00, 7.7737e+00, 8.0584e+00, 8.3536e+00,\n",
       "        8.6596e+00, 8.9769e+00, 9.3057e+00, 9.6466e+00, 1.0000e+01, 1.0366e+01,\n",
       "        1.0746e+01, 1.1140e+01, 1.1548e+01, 1.1971e+01, 1.2409e+01, 1.2864e+01,\n",
       "        1.3335e+01, 1.3824e+01, 1.4330e+01, 1.4855e+01, 1.5399e+01, 1.5963e+01,\n",
       "        1.6548e+01, 1.7154e+01, 1.7783e+01, 1.8434e+01, 1.9110e+01, 1.9810e+01,\n",
       "        2.0535e+01, 2.1288e+01, 2.2067e+01, 2.2876e+01, 2.3714e+01, 2.4582e+01,\n",
       "        2.5483e+01, 2.6416e+01, 2.7384e+01, 2.8387e+01, 2.9427e+01, 3.0505e+01,\n",
       "        3.1623e+01, 3.2781e+01, 3.3982e+01, 3.5227e+01, 3.6517e+01, 3.7855e+01,\n",
       "        3.9242e+01, 4.0679e+01, 4.2170e+01, 4.3714e+01, 4.5316e+01, 4.6976e+01,\n",
       "        4.8697e+01, 5.0481e+01, 5.2330e+01, 5.4247e+01, 5.6234e+01, 5.8294e+01,\n",
       "        6.0430e+01, 6.2643e+01, 6.4938e+01, 6.7317e+01, 6.9783e+01, 7.2339e+01,\n",
       "        7.4989e+01, 7.7737e+01, 8.0584e+01, 8.3536e+01, 8.6596e+01, 8.9769e+01,\n",
       "        9.3057e+01, 9.6466e+01, 1.0000e+02, 1.0366e+02, 1.0746e+02, 1.1140e+02,\n",
       "        1.1548e+02, 1.1971e+02, 1.2409e+02, 1.2864e+02, 1.3335e+02, 1.3824e+02,\n",
       "        1.4330e+02, 1.4855e+02, 1.5399e+02, 1.5963e+02, 1.6548e+02, 1.7154e+02,\n",
       "        1.7783e+02, 1.8434e+02, 1.9110e+02, 1.9810e+02, 2.0535e+02, 2.1288e+02,\n",
       "        2.2067e+02, 2.2876e+02, 2.3714e+02, 2.4582e+02, 2.5483e+02, 2.6416e+02,\n",
       "        2.7384e+02, 2.8387e+02, 2.9427e+02, 3.0505e+02, 3.1623e+02, 3.2781e+02,\n",
       "        3.3982e+02, 3.5227e+02, 3.6517e+02, 3.7855e+02, 3.9242e+02, 4.0679e+02,\n",
       "        4.2170e+02, 4.3714e+02, 4.5316e+02, 4.6976e+02, 4.8697e+02, 5.0481e+02,\n",
       "        5.2330e+02, 5.4247e+02, 5.6234e+02, 5.8294e+02, 6.0430e+02, 6.2643e+02,\n",
       "        6.4938e+02, 6.7317e+02, 6.9783e+02, 7.2339e+02, 7.4989e+02, 7.7737e+02,\n",
       "        8.0584e+02, 8.3536e+02, 8.6596e+02, 8.9769e+02, 9.3057e+02, 9.6466e+02,\n",
       "        1.0000e+03, 1.0366e+03, 1.0746e+03, 1.1140e+03, 1.1548e+03, 1.1971e+03,\n",
       "        1.2409e+03, 1.2864e+03, 1.3335e+03, 1.3824e+03, 1.4330e+03, 1.4855e+03,\n",
       "        1.5399e+03, 1.5963e+03, 1.6548e+03, 1.7154e+03, 1.7783e+03, 1.8434e+03,\n",
       "        1.9110e+03, 1.9810e+03, 2.0535e+03, 2.1288e+03, 2.2067e+03, 2.2876e+03,\n",
       "        2.3714e+03, 2.4582e+03, 2.5483e+03, 2.6416e+03, 2.7384e+03, 2.8387e+03,\n",
       "        2.9427e+03, 3.0505e+03, 3.1623e+03, 3.2781e+03, 3.3982e+03, 3.5227e+03,\n",
       "        3.6517e+03, 3.7855e+03, 3.9242e+03, 4.0679e+03, 4.2170e+03, 4.3714e+03,\n",
       "        4.5316e+03, 4.6976e+03, 4.8697e+03, 5.0481e+03, 5.2330e+03, 5.4247e+03,\n",
       "        5.6234e+03, 5.8294e+03, 6.0430e+03, 6.2643e+03, 6.4938e+03, 6.7317e+03,\n",
       "        6.9783e+03, 7.2339e+03, 7.4989e+03, 7.7737e+03, 8.0584e+03, 8.3536e+03,\n",
       "        8.6596e+03, 8.9769e+03, 9.3057e+03, 9.6466e+03])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_denominator = torch.pow(10000, (odd_i - 1)/d_model)\n",
    "even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator = even_denominator\n",
    "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_PE = torch.sin(position / denominator)\n",
    "odd_PE = torch.cos(position / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [8.4147e-01, 8.2186e-01, 8.0196e-01,  ..., 1.1140e-04, 1.0746e-04,\n",
       "         1.0366e-04],\n",
       "        [9.0930e-01, 9.3641e-01, 9.5814e-01,  ..., 2.2279e-04, 2.1492e-04,\n",
       "         2.0733e-04],\n",
       "        [1.4112e-01, 2.4509e-01, 3.4278e-01,  ..., 3.3419e-04, 3.2238e-04,\n",
       "         3.1099e-04]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(even_PE.shape)\n",
    "even_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "        [ 0.5403,  0.5697,  0.5974,  ...,  1.0000,  1.0000,  1.0000],\n",
       "        [-0.4161, -0.3509, -0.2863,  ...,  1.0000,  1.0000,  1.0000],\n",
       "        [-0.9900, -0.9695, -0.9394,  ...,  1.0000,  1.0000,  1.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  1.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  1.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 8.4147e-01,  5.4030e-01],\n",
       "         [ 8.2186e-01,  5.6969e-01],\n",
       "         [ 8.0196e-01,  5.9738e-01],\n",
       "         ...,\n",
       "         [ 1.1140e-04,  1.0000e+00],\n",
       "         [ 1.0746e-04,  1.0000e+00],\n",
       "         [ 1.0366e-04,  1.0000e+00]],\n",
       "\n",
       "        [[ 9.0930e-01, -4.1615e-01],\n",
       "         [ 9.3641e-01, -3.5090e-01],\n",
       "         [ 9.5814e-01, -2.8629e-01],\n",
       "         ...,\n",
       "         [ 2.2279e-04,  1.0000e+00],\n",
       "         [ 2.1492e-04,  1.0000e+00],\n",
       "         [ 2.0733e-04,  1.0000e+00]],\n",
       "\n",
       "        [[ 1.4112e-01, -9.8999e-01],\n",
       "         [ 2.4509e-01, -9.6950e-01],\n",
       "         [ 3.4278e-01, -9.3942e-01],\n",
       "         ...,\n",
       "         [ 3.3419e-04,  1.0000e+00],\n",
       "         [ 3.2238e-04,  1.0000e+00],\n",
       "         [ 3.1099e-04,  1.0000e+00]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "          1.0366e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "          2.0733e-04,  1.0000e+00],\n",
       "        [ 1.4112e-01, -9.8999e-01,  2.4509e-01,  ...,  1.0000e+00,\n",
       "          3.1099e-04,  1.0000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "          1.0366e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "          2.0733e-04,  1.0000e+00],\n",
       "        ...,\n",
       "        [-8.9797e-01, -4.4006e-01,  4.2620e-01,  ...,  9.9427e-01,\n",
       "          1.0317e-01,  9.9466e-01],\n",
       "        [-8.5547e-01,  5.1785e-01,  9.8628e-01,  ...,  9.9425e-01,\n",
       "          1.0327e-01,  9.9465e-01],\n",
       "        [-2.6461e-02,  9.9965e-01,  6.9756e-01,  ...,  9.9424e-01,\n",
       "          1.0337e-01,  9.9464e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(d_model=512, max_sequence_length=1000)\n",
    "pe.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.forward().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('myvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f10a24a426163f4969834cd78cacbc8a505b0e39e0a52f8aaabad16331e335f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
